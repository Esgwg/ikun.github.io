<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Es</title><link>https://Esgwg.github.io/ikun.github.io</link><description>Welcome to my blog!</description><copyright>Es</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://avatars.githubusercontent.com/u/101002150?v=4</url><title>avatar</title><link>https://Esgwg.github.io/ikun.github.io</link></image><lastBuildDate>Mon, 23 Dec 2024 15:01:03 +0000</lastBuildDate><managingEditor>Es</managingEditor><ttl>60</ttl><webMaster>Es</webMaster><item><title>高效通道注意力机制ECA</title><link>https://Esgwg.github.io/ikun.github.io/post/gao-xiao-tong-dao-zhu-yi-li-ji-zhi-ECA.html</link><description>[高效通道注意力机制ECA](https://mp.weixin.qq.com/s/DzShML1MBsq0Pdk0arC6sQ)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/gao-xiao-tong-dao-zhu-yi-li-ji-zhi-ECA.html</guid><pubDate>Mon, 23 Dec 2024 15:00:38 +0000</pubDate></item><item><title>局部重要性驱动注意力机制LIA</title><link>https://Esgwg.github.io/ikun.github.io/post/ju-bu-zhong-yao-xing-qu-dong-zhu-yi-li-ji-zhi-LIA.html</link><description>[局部重要性驱动注意力机制LIA](https://mp.weixin.qq.com/s/xHrlTafP5JdvVezYAaIB9A)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/ju-bu-zhong-yao-xing-qu-dong-zhu-yi-li-ji-zhi-LIA.html</guid><pubDate>Sun, 22 Dec 2024 15:55:45 +0000</pubDate></item><item><title>mamba线性注意力机制模块</title><link>https://Esgwg.github.io/ikun.github.io/post/mamba-xian-xing-zhu-yi-li-ji-zhi-mo-kuai.html</link><description>[mamba线性注意力机制模块](https://mp.weixin.qq.com/s/T0G2p32r0Tf_7rFajTwioA)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/mamba-xian-xing-zhu-yi-li-ji-zhi-mo-kuai.html</guid><pubDate>Sat, 21 Dec 2024 06:58:56 +0000</pubDate></item><item><title>挑战Transformer！Mamba的架构及实现（Pytorch）</title><link>https://Esgwg.github.io/ikun.github.io/post/tiao-zhan-Transformer%EF%BC%81Mamba-de-jia-gou-ji-shi-xian-%EF%BC%88Pytorch%EF%BC%89.html</link><description>[挑战Transformer！Mamba的架构及实现（Pytorch）](https://mp.weixin.qq.com/s/w_Sj7mcBvosorsMjh4Jwmg)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/tiao-zhan-Transformer%EF%BC%81Mamba-de-jia-gou-ji-shi-xian-%EF%BC%88Pytorch%EF%BC%89.html</guid><pubDate>Sat, 21 Dec 2024 06:53:34 +0000</pubDate></item><item><title>语义、位置、切片三重注意力CSAM</title><link>https://Esgwg.github.io/ikun.github.io/post/yu-yi-%E3%80%81-wei-zhi-%E3%80%81-qie-pian-san-zhong-zhu-yi-li-CSAM.html</link><description>[语义、位置、切片三重注意力CSAM](https://mp.weixin.qq.com/s/6c31_lVDVok220CUnThgdg)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/yu-yi-%E3%80%81-wei-zhi-%E3%80%81-qie-pian-san-zhong-zhu-yi-li-CSAM.html</guid><pubDate>Sat, 21 Dec 2024 06:42:35 +0000</pubDate></item><item><title>期刊配图：多种机器学习算法在递归特征筛选中的性能变化图示</title><link>https://Esgwg.github.io/ikun.github.io/post/qi-kan-pei-tu-%EF%BC%9A-duo-zhong-ji-qi-xue-xi-suan-fa-zai-di-gui-te-zheng-shai-xuan-zhong-de-xing-neng-bian-hua-tu-shi.html</link><description>[期刊配图：多种机器学习算法在递归特征筛选中的性能变化图示](https://mp.weixin.qq.com/s/gfh5Ocv4ATpcMRbwNnJAAg)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/qi-kan-pei-tu-%EF%BC%9A-duo-zhong-ji-qi-xue-xi-suan-fa-zai-di-gui-te-zheng-shai-xuan-zhong-de-xing-neng-bian-hua-tu-shi.html</guid><pubDate>Fri, 20 Dec 2024 16:22:57 +0000</pubDate></item><item><title>最先进的注意力：Orthogonal Channel Attention—正交通道注意力</title><link>https://Esgwg.github.io/ikun.github.io/post/zui-xian-jin-de-zhu-yi-li-%EF%BC%9AOrthogonal%20Channel%20Attention%E2%80%94-zheng-jiao-tong-dao-zhu-yi-li.html</link><description>[最先进的注意力：Orthogonal Channel Attention—正交通道注意力](https://mp.weixin.qq.com/s/839wuXmSJD3tXCPS3LVQ_w)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/zui-xian-jin-de-zhu-yi-li-%EF%BC%9AOrthogonal%20Channel%20Attention%E2%80%94-zheng-jiao-tong-dao-zhu-yi-li.html</guid><pubDate>Fri, 20 Dec 2024 14:08:47 +0000</pubDate></item><item><title>CAFM：卷积和注意力融合模块，即插即用，捕获细粒度局部信息和全局依赖关系</title><link>https://Esgwg.github.io/ikun.github.io/post/CAFM%EF%BC%9A-juan-ji-he-zhu-yi-li-rong-he-mo-kuai-%EF%BC%8C-ji-cha-ji-yong-%EF%BC%8C-bu-huo-xi-li-du-ju-bu-xin-xi-he-quan-ju-yi-lai-guan-xi.html</link><description>[CAFM：卷积和注意力融合模块，即插即用，捕获细粒度局部信息和全局依赖关系](https://mp.weixin.qq.com/s/wmb7B0XVIVc8JqbcULpHbg)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/CAFM%EF%BC%9A-juan-ji-he-zhu-yi-li-rong-he-mo-kuai-%EF%BC%8C-ji-cha-ji-yong-%EF%BC%8C-bu-huo-xi-li-du-ju-bu-xin-xi-he-quan-ju-yi-lai-guan-xi.html</guid><pubDate>Tue, 17 Dec 2024 11:10:51 +0000</pubDate></item><item><title>即插即用Efficient Non-Local Transformer Block</title><link>https://Esgwg.github.io/ikun.github.io/post/ji-cha-ji-yong-Efficient%20Non-Local%20Transformer%20Block.html</link><description>[即插即用Efficient Non-Local Transformer Block](https://mp.weixin.qq.com/s/KMzOrtHD-imfed2jVUINUA)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/ji-cha-ji-yong-Efficient%20Non-Local%20Transformer%20Block.html</guid><pubDate>Sun, 15 Dec 2024 11:28:20 +0000</pubDate></item><item><title>NeurIPS 条件卷积模块CondConv</title><link>https://Esgwg.github.io/ikun.github.io/post/NeurIPS%20-tiao-jian-juan-ji-mo-kuai-CondConv.html</link><description>[NeurIPS 条件卷积模块CondConv](https://mp.weixin.qq.com/s/MnutOKfNsO5FYglA8Zu9VA)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/NeurIPS%20-tiao-jian-juan-ji-mo-kuai-CondConv.html</guid><pubDate>Sat, 14 Dec 2024 05:40:25 +0000</pubDate></item><item><title>Vision Transformer的Pytorch代码实现和解读</title><link>https://Esgwg.github.io/ikun.github.io/post/Vision%20Transformer-de-Pytorch-dai-ma-shi-xian-he-jie-du.html</link><description>[Vision Transformer的Pytorch代码实现和解读](https://zhuanlan.zhihu.com/p/618623713)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/Vision%20Transformer-de-Pytorch-dai-ma-shi-xian-he-jie-du.html</guid><pubDate>Thu, 12 Dec 2024 08:35:58 +0000</pubDate></item><item><title>时间序列模型，Prophet</title><link>https://Esgwg.github.io/ikun.github.io/post/shi-jian-xu-lie-mo-xing-%EF%BC%8CProphet.html</link><description>[时间序列模型，Prophet](https://mp.weixin.qq.com/s/NUwG1M1gPlkziweK-RAY6Q)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/shi-jian-xu-lie-mo-xing-%EF%BC%8CProphet.html</guid><pubDate>Sun, 08 Dec 2024 05:43:07 +0000</pubDate></item><item><title>2024多级卷积模块MCM</title><link>https://Esgwg.github.io/ikun.github.io/post/2024-duo-ji-juan-ji-mo-kuai-MCM.html</link><description>[2024多级卷积模块MCM](https://mp.weixin.qq.com/s/pLEIuccEkjWddToQV5gdhQ)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/2024-duo-ji-juan-ji-mo-kuai-MCM.html</guid><pubDate>Tue, 03 Dec 2024 13:14:27 +0000</pubDate></item><item><title>用t-SNE实现数据降维</title><link>https://Esgwg.github.io/ikun.github.io/post/yong-t-SNE-shi-xian-shu-ju-jiang-wei.html</link><description>[用t-SNE实现数据降维](https://mp.weixin.qq.com/s/NzylnMP7mbcjx7cr5hhFvQ)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/yong-t-SNE-shi-xian-shu-ju-jiang-wei.html</guid><pubDate>Tue, 03 Dec 2024 13:08:49 +0000</pubDate></item><item><title>性能再升级！损失函数+注意力机制一举拿下高分</title><link>https://Esgwg.github.io/ikun.github.io/post/xing-neng-zai-sheng-ji-%EF%BC%81-sun-shi-han-shu-%2B-zhu-yi-li-ji-zhi-yi-ju-na-xia-gao-fen.html</link><description>注意论文2、5.&#13;
[性能再升级！损失函数+注意力机制一举拿下高分](https://mp.weixin.qq.com/s/-54y0heviN8WyRC7GE_zGA)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/xing-neng-zai-sheng-ji-%EF%BC%81-sun-shi-han-shu-%2B-zhu-yi-li-ji-zhi-yi-ju-na-xia-gao-fen.html</guid><pubDate>Sat, 30 Nov 2024 16:39:02 +0000</pubDate></item><item><title>AI全网最全最新的即插即用模块。包括卷积、注意力机制、下采样、特征融合模块等。</title><link>https://Esgwg.github.io/ikun.github.io/post/AI-quan-wang-zui-quan-zui-xin-de-ji-cha-ji-yong-mo-kuai-%E3%80%82-bao-kuo-juan-ji-%E3%80%81-zhu-yi-li-ji-zhi-%E3%80%81-xia-cai-yang-%E3%80%81-te-zheng-rong-he-mo-kuai-deng-%E3%80%82.html</link><description>[AI全网最全最新的即插即用模块。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/AI-quan-wang-zui-quan-zui-xin-de-ji-cha-ji-yong-mo-kuai-%E3%80%82-bao-kuo-juan-ji-%E3%80%81-zhu-yi-li-ji-zhi-%E3%80%81-xia-cai-yang-%E3%80%81-te-zheng-rong-he-mo-kuai-deng-%E3%80%82.html</guid><pubDate>Sat, 30 Nov 2024 15:12:04 +0000</pubDate></item><item><title>（云服务器）以目录创建的conda环境添加到jupyter的kernel中</title><link>https://Esgwg.github.io/ikun.github.io/post/%EF%BC%88-yun-fu-wu-qi-%EF%BC%89-yi-mu-lu-chuang-jian-de-conda-huan-jing-tian-jia-dao-jupyter-de-kernel-zhong.html</link><description>[场景：由于某些原因，服务器上的conda环境不能通过--name的方式创建，只能通过指定目录即-p的方式，在这种情况下该环境在conda env list中没有显示，无法在jupyter kernel中搜到，只能手动添加。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/%EF%BC%88-yun-fu-wu-qi-%EF%BC%89-yi-mu-lu-chuang-jian-de-conda-huan-jing-tian-jia-dao-jupyter-de-kernel-zhong.html</guid><pubDate>Sat, 30 Nov 2024 13:03:48 +0000</pubDate></item><item><title>即插即用轻量化自适应提取模块LAE</title><link>https://Esgwg.github.io/ikun.github.io/post/ji-cha-ji-yong-qing-liang-hua-zi-shi-ying-ti-qu-mo-kuai-LAE.html</link><description>[即插即用轻量化自适应提取模块LAE](https://mp.weixin.qq.com/s/11CnPkPv0Ae6shay194XAw)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/ji-cha-ji-yong-qing-liang-hua-zi-shi-ying-ti-qu-mo-kuai-LAE.html</guid><pubDate>Sat, 30 Nov 2024 10:55:18 +0000</pubDate></item><item><title>深度学习优化要诀：如何选择损失函数</title><link>https://Esgwg.github.io/ikun.github.io/post/shen-du-xue-xi-you-hua-yao-jue-%EF%BC%9A-ru-he-xuan-ze-sun-shi-han-shu.html</link><description>[深度学习优化要诀：如何选择损失函数](https://mp.weixin.qq.com/s/04eN2wGj4r43V07KiTU4Hw)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/shen-du-xue-xi-you-hua-yao-jue-%EF%BC%9A-ru-he-xuan-ze-sun-shi-han-shu.html</guid><pubDate>Sat, 30 Nov 2024 06:54:00 +0000</pubDate></item><item><title>25年【Mamba 架构+医学图像分割】必将迎来新爆发！</title><link>https://Esgwg.github.io/ikun.github.io/post/25-nian-%E3%80%90Mamba%20-jia-gou-%2B-yi-xue-tu-xiang-fen-ge-%E3%80%91-bi-jiang-ying-lai-xin-bao-fa-%EF%BC%81.html</link><description>[25年【Mamba 架构+医学图像分割】必将迎来新爆发！](https://mp.weixin.qq.com/s/4XGbq1sJ8JQgONwx3HQx7w)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/25-nian-%E3%80%90Mamba%20-jia-gou-%2B-yi-xue-tu-xiang-fen-ge-%E3%80%91-bi-jiang-ying-lai-xin-bao-fa-%EF%BC%81.html</guid><pubDate>Fri, 29 Nov 2024 13:53:30 +0000</pubDate></item><item><title>顶会新宠！KAN-LSTM完美融合新方案</title><link>https://Esgwg.github.io/ikun.github.io/post/ding-hui-xin-chong-%EF%BC%81KAN-LSTM-wan-mei-rong-he-xin-fang-an.html</link><description>[顶会新宠！KAN-LSTM完美融合新方案](https://mp.weixin.qq.com/s/beWCCMAlQ85df2VYe0ystg)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/ding-hui-xin-chong-%EF%BC%81KAN-LSTM-wan-mei-rong-he-xin-fang-an.html</guid><pubDate>Fri, 29 Nov 2024 13:52:55 +0000</pubDate></item><item><title>论文解读：KAN: Kolmogorov–Arnold Networks。</title><link>https://Esgwg.github.io/ikun.github.io/post/lun-wen-jie-du-%EF%BC%9AKAN-%20Kolmogorov%E2%80%93Arnold%20Networks%E3%80%82.html</link><description>[论文解读：KAN: Kolmogorov–Arnold Networks](https://blog.csdn.net/qq_27590277/article/details/138555114)&#13;
多维函数可以通过一系列的一维函数操作和简单的加法来构建。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/lun-wen-jie-du-%EF%BC%9AKAN-%20Kolmogorov%E2%80%93Arnold%20Networks%E3%80%82.html</guid><pubDate>Fri, 29 Nov 2024 13:51:39 +0000</pubDate></item><item><title>2024即插即用分层特征融合模块HFF(用于医学图像分类)</title><link>https://Esgwg.github.io/ikun.github.io/post/2024-ji-cha-ji-yong-fen-ceng-te-zheng-rong-he-mo-kuai-HFF%28-yong-yu-yi-xue-tu-xiang-fen-lei-%29.html</link><description>[2024即插即用分层特征融合模块HFF](https://mp.weixin.qq.com/s/zq5d1vAY-Sqwn5E6a8edhg)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/2024-ji-cha-ji-yong-fen-ceng-te-zheng-rong-he-mo-kuai-HFF%28-yong-yu-yi-xue-tu-xiang-fen-lei-%29.html</guid><pubDate>Thu, 28 Nov 2024 15:45:54 +0000</pubDate></item><item><title>PyTorch中的Module详解：神经网络核心组件</title><link>https://Esgwg.github.io/ikun.github.io/post/PyTorch-zhong-de-Module-xiang-jie-%EF%BC%9A-shen-jing-wang-luo-he-xin-zu-jian.html</link><description>[PyTorch中的Module详解：神经网络核心组件](https://mp.weixin.qq.com/s/locyHU5FXwQ2J7snmslG1g)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/PyTorch-zhong-de-Module-xiang-jie-%EF%BC%9A-shen-jing-wang-luo-he-xin-zu-jian.html</guid><pubDate>Thu, 28 Nov 2024 15:36:52 +0000</pubDate></item><item><title>即插即用时空动态特征提取和优化的轻量型注意力模块GAU</title><link>https://Esgwg.github.io/ikun.github.io/post/ji-cha-ji-yong-shi-kong-dong-tai-te-zheng-ti-qu-he-you-hua-de-qing-liang-xing-zhu-yi-li-mo-kuai-GAU.html</link><description>[即插即用时空动态特征提取和优化的轻量型注意力模块GAU](https://mp.weixin.qq.com/s/UqMmNnQTSKSvD8xK942guQ)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/ji-cha-ji-yong-shi-kong-dong-tai-te-zheng-ti-qu-he-you-hua-de-qing-liang-xing-zhu-yi-li-mo-kuai-GAU.html</guid><pubDate>Thu, 28 Nov 2024 04:48:41 +0000</pubDate></item><item><title>最强总结机器学习模型，Adaboost ！！</title><link>https://Esgwg.github.io/ikun.github.io/post/zui-qiang-zong-jie-ji-qi-xue-xi-mo-xing-%EF%BC%8CAdaboost%20%EF%BC%81%EF%BC%81.html</link><description>[最强总结机器学习模型，Adaboost ！！](https://mp.weixin.qq.com/s/dioK6tDNh1LBvSM9z0dy6g)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/zui-qiang-zong-jie-ji-qi-xue-xi-mo-xing-%EF%BC%8CAdaboost%20%EF%BC%81%EF%BC%81.html</guid><pubDate>Thu, 28 Nov 2024 04:42:51 +0000</pubDate></item><item><title>新 SHAP 图：Violin 和 Heatmap</title><link>https://Esgwg.github.io/ikun.github.io/post/xin-%20SHAP%20-tu-%EF%BC%9AViolin%20-he-%20Heatmap.html</link><description>[新 SHAP 图：Violin 和 Heatmap](https://mp.weixin.qq.com/s/6RJFjPFqqXrm7XKoFffaig)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/xin-%20SHAP%20-tu-%EF%BC%9AViolin%20-he-%20Heatmap.html</guid><pubDate>Thu, 28 Nov 2024 04:38:21 +0000</pubDate></item><item><title>GBDT、XGBoost、LightGBM，树模型全面对比 ！！</title><link>https://Esgwg.github.io/ikun.github.io/post/GBDT%E3%80%81XGBoost%E3%80%81LightGBM%EF%BC%8C-shu-mo-xing-quan-mian-dui-bi-%20%EF%BC%81%EF%BC%81.html</link><description>[GBDT、XGBoost、LightGBM，树模型全面对比 ！！](https://mp.weixin.qq.com/s/LwCNJP3Z51Hn2aclSvYQ_w)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/GBDT%E3%80%81XGBoost%E3%80%81LightGBM%EF%BC%8C-shu-mo-xing-quan-mian-dui-bi-%20%EF%BC%81%EF%BC%81.html</guid><pubDate>Mon, 25 Nov 2024 06:59:41 +0000</pubDate></item><item><title>特征选择方法</title><link>https://Esgwg.github.io/ikun.github.io/post/te-zheng-xuan-ze-fang-fa.html</link><description>[特征选择方法](https://mp.weixin.qq.com/s/aAbVoLH789Z22sH0S5Wwpg)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/te-zheng-xuan-ze-fang-fa.html</guid><pubDate>Fri, 22 Nov 2024 04:58:07 +0000</pubDate></item><item><title>XGBoost</title><link>https://Esgwg.github.io/ikun.github.io/post/XGBoost.html</link><description>[XGBoost](https://mp.weixin.qq.com/s/8Fnm_YbtuqfPAsedqwBtxw)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/XGBoost.html</guid><pubDate>Wed, 20 Nov 2024 15:41:07 +0000</pubDate></item><item><title>可解释性机器学习——SHAP</title><link>https://Esgwg.github.io/ikun.github.io/post/ke-jie-shi-xing-ji-qi-xue-xi-%E2%80%94%E2%80%94SHAP.html</link><description>[可解释性机器学习——SHAP](https://mp.weixin.qq.com/s/4mz63XmNu0qqEB1ZUitkIA)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/ke-jie-shi-xing-ji-qi-xue-xi-%E2%80%94%E2%80%94SHAP.html</guid><pubDate>Wed, 20 Nov 2024 07:57:09 +0000</pubDate></item><item><title>UU在线工具——多款文本、编程、数学、图像、文件转换、音视频等工具</title><link>https://Esgwg.github.io/ikun.github.io/post/UU-zai-xian-gong-ju-%E2%80%94%E2%80%94-duo-kuan-wen-ben-%E3%80%81-bian-cheng-%E3%80%81-shu-xue-%E3%80%81-tu-xiang-%E3%80%81-wen-jian-zhuan-huan-%E3%80%81-yin-shi-pin-deng-gong-ju.html</link><description>[UU在线工具](https://uutool.cn/)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/UU-zai-xian-gong-ju-%E2%80%94%E2%80%94-duo-kuan-wen-ben-%E3%80%81-bian-cheng-%E3%80%81-shu-xue-%E3%80%81-tu-xiang-%E3%80%81-wen-jian-zhuan-huan-%E3%80%81-yin-shi-pin-deng-gong-ju.html</guid><pubDate>Sun, 17 Nov 2024 07:13:25 +0000</pubDate></item><item><title>Lightly: 在线运行多种代码</title><link>https://Esgwg.github.io/ikun.github.io/post/Lightly-%20-zai-xian-yun-xing-duo-zhong-dai-ma.html</link><description>[在线运行多种代码](https://lightly.teamcode.com/dashboard)&#13;
![image](https://github.com/user-attachments/assets/9d7c685f-f4e3-4388-b273-6410d0d08f63)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/Lightly-%20-zai-xian-yun-xing-duo-zhong-dai-ma.html</guid><pubDate>Sat, 16 Nov 2024 09:07:41 +0000</pubDate></item><item><title>在线运行MATLAB代码</title><link>https://Esgwg.github.io/ikun.github.io/post/zai-xian-yun-xing-MATLAB-dai-ma.html</link><description>[在线运行MATLAB代码](https://www.tutorialspoint.com/execute_matlab_online.php)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/zai-xian-yun-xing-MATLAB-dai-ma.html</guid><pubDate>Sat, 16 Nov 2024 09:06:52 +0000</pubDate></item><item><title>IP地址查询</title><link>https://Esgwg.github.io/ikun.github.io/post/IP-di-zhi-cha-xun.html</link><description>[单个IP地址查询](https://www.qqzeng.com/ip/)&#13;
[多个/单个IP地址查询](https://uutool.cn/ip-batch/)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/IP-di-zhi-cha-xun.html</guid><pubDate>Thu, 14 Nov 2024 13:49:51 +0000</pubDate></item><item><title>最强异常检测算法，自编码器 ！！；AutoEncoder.py</title><link>https://Esgwg.github.io/ikun.github.io/post/zui-qiang-yi-chang-jian-ce-suan-fa-%EF%BC%8C-zi-bian-ma-qi-%20%EF%BC%81%EF%BC%81%EF%BC%9BAutoEncoder.py.html</link><description>[最强异常检测算法，自编码器 ！！](https://mp.weixin.qq.com/s/wvJM4sKsmCHJGchWJTz8zw)&#13;
；&#13;
&#13;
```python&#13;
'''&#13;
autoencoder based anomaly detection model&#13;
'''&#13;
import torch&#13;
import torch.nn as nn&#13;
import torch.optim as optim&#13;
import torch.utils.data as Data&#13;
import numpy as np&#13;
import matplotlib.pyplot as plt&#13;
from sklearn import metrics&#13;
import copy&#13;
# plt.switch_backend('Agg')&#13;
&#13;
from general_utils import DEVICE&#13;
&#13;
epoches = 20&#13;
lr = 1e-4&#13;
weight_decay = 1.e-7&#13;
batch_size = 1024&#13;
percentage = 0.99&#13;
&#13;
device = DEVICE&#13;
criterion = nn.MSELoss()&#13;
getMSEvec = nn.MSELoss(reduction='none')&#13;
&#13;
&#13;
class autoencoder(nn.Module):&#13;
    def __init__(self, feature_size, criter='rmse'): # criter = ['rmse', 'mse'] &#13;
        super(autoencoder, self).__init__()&#13;
        self.encoder = nn.Sequential(nn.Linear(feature_size, int(feature_size*0.75)),&#13;
                                     nn.ReLU(True),&#13;
                                     nn.Linear(int(feature_size*0.75), int(feature_size*0.5)),&#13;
                                     nn.ReLU(True),&#13;
                                     nn.Linear(int(feature_size*0.5),int(feature_size*0.25)),&#13;
                                     nn.ReLU(True),&#13;
                                     nn.Linear(int(feature_size*0.25),int(feature_size*0.1)))&#13;
&#13;
        self.decoder = nn.Sequential(nn.Linear(int(feature_size*0.1),int(feature_size*0.25)),&#13;
                                     nn.ReLU(True),&#13;
                                     nn.Linear(int(feature_size*0.25),int(feature_size*0.5)),&#13;
                                     nn.ReLU(True),&#13;
                                     nn.Linear(int(feature_size*0.5),int(feature_size*0.75)),&#13;
                                     nn.ReLU(True),&#13;
                                     nn.Linear(int(feature_size*0.75),int(feature_size)),&#13;
                                     )&#13;
        &#13;
        self.thres = np.Inf&#13;
        self.criter = criter&#13;
        print(f'NOTICE: use {self.criter} as the criteration of reconstruction error')&#13;
&#13;
    def forward(self, x):&#13;
        encode = self.encoder(x)&#13;
        # print('encode', encode)&#13;
        decode = self.decoder(encode)&#13;
        # print('decode', decode)&#13;
        return decode&#13;
    &#13;
    # update anomaly detection threshold&#13;
    def update_thres(self, thres):&#13;
        self.thres = thres&#13;
&#13;
&#13;
def se2rmse(a):&#13;
    return torch.sqrt(sum(a.t())/a.shape[1])&#13;
&#13;
def train(X_train, feature_size, epoches=epoches, lr=lr, percentage=percentage, weight_decay=weight_decay, verbose=True, thres_criter='rmse'):&#13;
    config = {&#13;
        'epoches': epoches,&#13;
        'lr':lr,&#13;
        'percentage':percentage,&#13;
        'weight_decay':weight_decay,&#13;
        'device':device,&#13;
    }&#13;
    if verbose:&#13;
        print('Hyper parameter config:', config)&#13;
        &#13;
    model = autoencoder(feature_size, thres_criter).to(device)&#13;
    optimizier = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)&#13;
    model.train()&#13;
&#13;
    X_train = torch.from_numpy(X_train).type(torch.float).to(device)&#13;
    torch_dataset = Data.TensorDataset(X_train, X_train)&#13;
    loader = Data.DataLoader(&#13;
        dataset=torch_dataset,&#13;
        batch_size=batch_size,&#13;
        shuffle=True,&#13;
    )&#13;
    &#13;
    for epoch in range(epoches):&#13;
        for step, (batch_x, batch_y) in enumerate(loader):&#13;
            output = model(batch_x)&#13;
            loss = criterion(output, batch_y)&#13;
            optimizier.zero_grad()&#13;
            loss.backward()&#13;
            optimizier.step()&#13;
            # if step % 10 == 0 :&#13;
        if verbose:&#13;
            print('epoch:{}/{}'.format(epoch,epoches), '|Loss:', loss.item())&#13;
    &#13;
    model.eval()&#13;
    output = model(X_train)&#13;
    if thres_criter == 'rmse':&#13;
        mse_vec = getMSEvec(output,X_train)&#13;
        rmse_vec = se2rmse(mse_vec).cpu().data.numpy()&#13;
        if verbose:&#13;
            print('max AD score',max(rmse_vec))&#13;
        thres = max(rmse_vec)&#13;
        rmse_vec.sort()&#13;
        pctg = percentage&#13;
        thres = rmse_vec[int(len(rmse_vec)*pctg)]&#13;
    elif thres_criter == 'mse':&#13;
        mse_vec = torch.mean(getMSEvec(X_train, output), dim=1).cpu().data.numpy()&#13;
        if verbose:&#13;
            print('max AD score',max(mse_vec))&#13;
        thres = max(mse_vec)&#13;
        mse_vec.sort()&#13;
        pctg = percentage&#13;
        thres = mse_vec[int(len(mse_vec)*pctg)]&#13;
    else:&#13;
        print('Unknown criterion for selecting threshold', thres_criter)&#13;
        exit(-1)&#13;
        &#13;
    model.thres = thres&#13;
    if verbose:&#13;
        print(f'Threshold is: {thres} (at percentage {percentage})' )&#13;
&#13;
    return model&#13;
&#13;
# use X_valid to decide the best model&#13;
def train_valid(X_train, feature_size, X_valid, y_valid, &#13;
                epoches=epoches, lr=lr, weight_decay=weight_decay, batch_size=batch_size, &#13;
                percentage=0.99, thres_criter='rmse', verbose=True, debug=False, opt='Adam'):&#13;
    config = {&#13;
        'epoches': epoches,&#13;
        'lr':lr,&#13;
        'percentage':percentage,&#13;
        'weight_decay':weight_decay,&#13;
        'device':device,&#13;
    }&#13;
    if verbose:&#13;
        print('Hyper parameter config:', config)&#13;
        &#13;
    model = autoencoder(feature_size, thres_criter).to(device)&#13;
    if opt == 'Adam':&#13;
        optimizier = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)&#13;
    elif opt == 'SGD':&#13;
        optimizier = optim.SGD(model.parameters(), lr=lr)&#13;
    else: &#13;
        raise RuntimeError(f'Unknown optimizier: {opt}')&#13;
&#13;
    X_train = torch.from_numpy(X_train).type(torch.float).to(device)  &#13;
    torch_dataset = Data.TensorDataset(X_train, X_train)&#13;
    loader = Data.DataLoader(&#13;
        dataset=torch_dataset,&#13;
        batch_size=batch_size,&#13;
        shuffle=True,&#13;
    )&#13;
    &#13;
    best_model, best_auc, best_thres =  None, -np.Inf, None&#13;
&#13;
    for epoch in range(epoches):&#13;
        model.train()&#13;
        for step, (batch_x, batch_y) in enumerate(loader):&#13;
            output = model(batch_x)&#13;
            loss = criterion(output, batch_y)&#13;
            optimizier.zero_grad()&#13;
            loss.backward()&#13;
            optimizier.step()&#13;
        if verbose:&#13;
            print('epoch:{}/{}'.format(epoch,epoches), '|Loss:', loss.item())&#13;
&#13;
        model.eval()&#13;
        # get raw threshold for model &#13;
        output = model(X_train)&#13;
        if thres_criter == 'rmse':&#13;
            mse_vec = getMSEvec(output,X_train)&#13;
            rmse_vec = se2rmse(mse_vec).cpu().data.numpy()&#13;
            thres = max(rmse_vec)&#13;
            rmse_vec.sort()&#13;
            pctg = percentage&#13;
            thres = rmse_vec[int(len(rmse_vec)*pctg)]&#13;
        elif thres_criter == 'mse':&#13;
            mse_vec = torch.mean(getMSEvec(X_train, output), dim=1).cpu().data.numpy()&#13;
            thres = max(mse_vec)&#13;
            mse_vec.sort()&#13;
            pctg = percentage&#13;
            thres = mse_vec[int(len(mse_vec)*pctg)]&#13;
        else:&#13;
            print('Unknown criterion for selecting threshold', thres_criter)&#13;
            exit(-1)&#13;
        model.thres = thres&#13;
&#13;
        _, y_valid_rmse = test(model, X_valid)&#13;
        roc_auc, o_thres = eval_roc(y_valid_rmse, y_valid, thres_max=model.thres*1.5, plot=False, verbose=False)&#13;
        if roc_auc &gt; best_auc:&#13;
            best_auc = roc_auc&#13;
            best_thres = o_thres&#13;
            best_model = copy.deepcopy(model)&#13;
            model.thres = best_thres&#13;
            y_valid_pred, _ = test(model, X_valid)&#13;
            tpr, fpr = TPR_FPR(y_valid_pred, y_valid, model.thres, verbose=False)&#13;
            if verbose: print(f'- update model! valid: roc auc is {best_auc:.5f}, tpr: {tpr:.5f}, fpr:{fpr:.5f}')&#13;
        elif debug:&#13;
            y_valid_pred, _ = test(model, X_valid)&#13;
            tpr, fpr = TPR_FPR(y_valid_pred, y_valid, o_thres, verbose=False)&#13;
            print(f'(- NOT update, valid: roc auc is {roc_auc:.5f}, tpr: {tpr:.5f}, fpr:{fpr:.5f})')&#13;
&#13;
    if verbose:&#13;
        print(f'Threshold is: {model.thres} (at percentage {percentage})' )&#13;
&#13;
    return best_model&#13;
&#13;
&#13;
&#13;
def train_pos_sampling(X_train_ben, X_train_pos, feature_size, pos_weight = 1.,&#13;
                       epoches=epoches, lr=lr, weight_decay=weight_decay, batch_size=batch_size, &#13;
                       percentage=0.99, thres_criter='rmse', verbose=True, debug=False, opt='Adam',&#13;
                       X_valid = None, y_valid = None, # if not None, will use validation set to choose best model&#13;
                       ):&#13;
    # clip to make sure X_train_pos and X_train_ben is with the same size&#13;
    if len(X_train_pos) &gt;= len(X_train_ben):&#13;
        X_train_pos = X_train_pos[:len(X_train_ben)]&#13;
    else:&#13;
        repeats = -(-len(X_train_ben)//len(X_train_pos))&#13;
        X_train_pos = np.tile(X_train_pos, (repeats, 1))&#13;
        X_train_pos = X_train_pos[:len(X_train_ben)]&#13;
&#13;
    config = {&#13;
        'epoches': epoches,&#13;
        'lr':lr,&#13;
        'percentage':percentage,&#13;
        'weight_decay':weight_decay,&#13;
        'device':device,&#13;
    }&#13;
    if verbose:&#13;
        print('Hyper parameter config:', config)&#13;
        &#13;
    model = autoencoder(feature_size, thres_criter).to(device)&#13;
    if opt == 'Adam':&#13;
        optimizier = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)&#13;
    elif opt == 'SGD':&#13;
        optimizier = optim.SGD(model.parameters(), lr=lr)&#13;
    else: &#13;
        raise RuntimeError(f'Unknown optimizier: {opt}')&#13;
&#13;
    X_train_ben = torch.from_numpy(X_train_ben).type(torch.float).to(device)&#13;
    X_train_pos = torch.from_numpy(X_train_pos).type(torch.float).to(device)&#13;
&#13;
    torch_dataset = Data.TensorDataset(X_train_ben, X_train_pos)&#13;
    loader = Data.DataLoader(&#13;
        dataset=torch_dataset,&#13;
        batch_size=batch_size,&#13;
        shuffle=True,&#13;
    )&#13;
    &#13;
    best_model, best_auc, best_thres =  None, -np.Inf, None&#13;
    Bound = nn.ReLU()&#13;
    MAX_THRES = 4.&#13;
    &#13;
    for epoch in range(epoches):&#13;
        model.train()&#13;
        for step, (batch_x_neg, batch_x_pos) in enumerate(loader):&#13;
            output_neg = model(batch_x_neg)&#13;
            loss_neg = criterion(output_neg, batch_x_neg)&#13;
            output_pos = model(batch_x_pos)&#13;
            loss_pos = Bound(MAX_THRES-criterion(output_pos, batch_x_pos))&#13;
            loss = loss_neg + pos_weight * loss_pos&#13;
            optimizier.zero_grad()&#13;
            loss.backward()&#13;
            optimizier.step()&#13;
&#13;
        if verbose:&#13;
            print('epoch:{}/{}'.format(epoch,epoches), '|Loss:', loss.item(), f'(neg: {loss_neg.item()}, pos:{loss_pos.item()})')&#13;
&#13;
        if (X_valid is not None and y_valid is not None) or (epoch == epoches-1):&#13;
            model.eval()&#13;
            # get raw threshold for model &#13;
            output = model(X_train_ben)&#13;
            if thres_criter == 'rmse':&#13;
                mse_vec = getMSEvec(output,X_train_ben)&#13;
                rmse_vec = se2rmse(mse_vec).cpu().data.numpy()&#13;
                thres = max(rmse_vec)&#13;
                rmse_vec.sort()&#13;
                pctg = percentage&#13;
                thres = rmse_vec[int(len(rmse_vec)*pctg)]&#13;
            elif thres_criter == 'mse':&#13;
                mse_vec = torch.mean(getMSEvec(X_train_ben, output), dim=1).cpu().data.numpy()&#13;
                thres = max(mse_vec)&#13;
                mse_vec.sort()&#13;
                pctg = percentage&#13;
                thres = mse_vec[int(len(mse_vec)*pctg)]&#13;
            else:&#13;
                print('Unknown criterion for selecting threshold', thres_criter)&#13;
                exit(-1)&#13;
            model.thres = thres&#13;
&#13;
        if X_valid is not None and y_valid is not None:&#13;
            _, y_valid_rmse = test(model, X_valid)&#13;
            roc_auc, o_thres = eval_roc(y_valid_rmse, y_valid, thres_max=model.thres*1.5, plot=False, verbose=False)&#13;
            if roc_auc &gt; best_auc:&#13;
                best_auc = roc_auc&#13;
                best_thres = o_thres&#13;
                best_model = copy.deepcopy(model)&#13;
                model.thres = best_thres&#13;
                y_valid_pred, _ = test(model, X_valid)&#13;
                tpr, fpr = TPR_FPR(y_valid_pred, y_valid, model.thres, verbose=False)&#13;
                if verbose: print(f'- update model! valid: roc auc is {best_auc:.5f}, tpr: {tpr:.5f}, fpr:{fpr:.5f}')&#13;
            elif debug:&#13;
                y_valid_pred, _ = test(model, X_valid)&#13;
                tpr, fpr = TPR_FPR(y_valid_pred, y_valid, o_thres, verbose=False)&#13;
                print(f'(- NOT update, valid: roc auc is {roc_auc:.5f}, tpr: {tpr:.5f}, fpr:{fpr:.5f})')&#13;
        else:&#13;
            best_model = model&#13;
&#13;
    if verbose:&#13;
        print(f'Threshold is: {model.thres} (at percentage {percentage})' )&#13;
&#13;
    return best_model&#13;
&#13;
&#13;
@torch.no_grad()&#13;
def test(model, X_test, thres=None):&#13;
    if thres is None:&#13;
        thres = model.thres &#13;
    model.eval()&#13;
    X_test = torch.from_numpy(X_test).type(torch.float)    &#13;
    X_test = X_test.to(device)&#13;
    output = model(X_test)&#13;
    if model.criter == 'rmse':&#13;
        mse_vec = getMSEvec(output,X_test)&#13;
        rmse_vec = se2rmse(mse_vec).cpu().data.numpy()&#13;
        idx_mal = np.where(rmse_vec&gt;thres)&#13;
        ano_score = rmse_vec&#13;
    elif model.criter == 'mse':&#13;
        mse_vec = torch.mean(getMSEvec(X_test, output), dim=1).cpu().data.numpy()&#13;
        idx_mal = np.where(mse_vec&gt;thres)&#13;
        ano_score = mse_vec&#13;
    else:&#13;
        raise NotImplementedError&#13;
    &#13;
     &#13;
    y_pred = np.asarray([0] * len(ano_score))&#13;
    y_pred[idx_mal] = 1&#13;
&#13;
    return y_pred, ano_score&#13;
&#13;
&#13;
def test_plot(rmse_vec, thres, file_name = None, label = None):&#13;
    plt.figure()&#13;
    plt.plot(np.linspace(0,len(rmse_vec)-1,len(rmse_vec)),[thres]*len(rmse_vec),c='black',label='99th-threshold')&#13;
    # plt.ylim(0,thres*2.)&#13;
&#13;
    if label is not None:&#13;
        idx = np.where(label==0)[0]&#13;
        plt.scatter(idx, rmse_vec[idx], s=8, color='blue', alpha=0.4, label='Normal')&#13;
        &#13;
        idx = np.where(label==1)[0]&#13;
        plt.scatter(idx, rmse_vec[idx], s=8, color='red', alpha=0.7, label='Anomalies')&#13;
    else:&#13;
        plt.scatter(np.linspace(0,len(rmse_vec)-1,len(rmse_vec)),rmse_vec,s=8,alpha=0.4, label='Test samples' )&#13;
    &#13;
    plt.legend()&#13;
    plt.xlabel('Sample NO.')&#13;
    plt.ylabel('Anomaly Score (RMSE)')&#13;
    plt.title('Per-sample Score')&#13;
    if file_name is None:&#13;
        plt.show()&#13;
    else:&#13;
        plt.rcParams.update({'figure.dpi':300})&#13;
        plt.savefig(file_name)&#13;
&#13;
&#13;
&#13;
def TPR_FPR(y_prob, y_true, thres, verbose=True): &#13;
    y_true = np.asarray(y_true)&#13;
    y_prob = np.asarray(y_prob)&#13;
    y_pred = np.where(y_prob &gt;= thres, 1, 0)&#13;
&#13;
    fp = np.sum((y_pred == 1) &amp; (y_true == 0))&#13;
    tp = np.sum((y_pred == 1) &amp; (y_true == 1))&#13;
    fn = np.sum((y_pred == 0) &amp; (y_true == 1))&#13;
    tn = np.sum((y_pred == 0) &amp; (y_true == 0))&#13;
&#13;
    fpr = (fp / (fp + tn + 1e-10))&#13;
    tpr = (tp / (tp + fn + 1e-10))&#13;
    &#13;
    if verbose:&#13;
        print('TPR:', tpr, 'FPR:', fpr,)&#13;
        print('TN:', tn, 'TP:', tp, 'FP:', fp, 'FN:', fn)&#13;
        &#13;
    return tpr, fpr&#13;
&#13;
&#13;
def multi_fpr_tpr(y_prob, y_true, thres_max, thres_min=0, split = 300, is_P_mal=True): &#13;
    y_true = np.asarray(y_true)&#13;
    y_prob = np.asarray(y_prob)&#13;
    fpr = []&#13;
    tpr = []&#13;
&#13;
    thresholds = np.linspace(thres_min, thres_max, split)&#13;
    for threshold in thresholds:&#13;
        if is_P_mal: &#13;
            y_pred = np.where(y_prob &gt;= threshold, 1, 0)&#13;
        else:&#13;
            y_pred = np.where(y_prob &lt;= threshold, 1, 0)&#13;
&#13;
        fp = np.sum((y_pred == 1) &amp; (y_true == 0))&#13;
        tp = np.sum((y_pred == 1) &amp; (y_true == 1))&#13;
&#13;
        fn = np.sum((y_pred == 0) &amp; (y_true == 1))&#13;
        tn = np.sum((y_pred == 0) &amp; (y_true == 0))&#13;
&#13;
        # print('fp+tn', fp+tn, 'tp + fn', tp + fn)&#13;
        fpr.append(fp / (fp + tn))&#13;
        tpr.append(tp / (tp + fn))&#13;
&#13;
    return fpr, tpr, thresholds&#13;
&#13;
def eval_roc(probs, labels, thres_max, thres_min=0, split=300, is_P_mal=True, plot=True, verbose=True):&#13;
    fprs, tprs, thresholds = multi_fpr_tpr(probs, labels, thres_max, thres_min=thres_min, split=split, is_P_mal=is_P_mal)&#13;
    roc_auc = metrics.auc(fprs, tprs)&#13;
    if verbose: print('roc_auc:',roc_auc)&#13;
    &#13;
    if plot:&#13;
        plt.figure()&#13;
        plt.title('Receiver Operating Characteristic')&#13;
        plt.plot(fprs, tprs, 'b', label = 'AUC = %0.2f' % roc_auc)&#13;
        plt.legend(loc = 'lower right')&#13;
        plt.xlim([0, 1])&#13;
        plt.ylim([0, 1])&#13;
        plt.ylabel('True Positive Rate')&#13;
        plt.xlabel('False Positive Rate')&#13;
        plt.show()&#13;
    &#13;
    optimal_idx = np.argmax(np.asarray(tprs) - np.asarray(fprs))&#13;
    optimal_threshold = thresholds[optimal_idx]&#13;
    return roc_auc, optimal_threshold&#13;
&#13;
class Normalizer:&#13;
    def __init__(self, train_data, clip=False, delta=1e-10):&#13;
        self.train_min = np.min(train_data, axis=0)&#13;
        self.train_max = np.max(train_data, axis=0)&#13;
        self.clip = clip&#13;
        self.delta = delta&#13;
&#13;
    def transform(self, data):&#13;
        return (data - self.train_min) / (self.train_max - self.train_min + self.delta)&#13;
&#13;
    def denorm(self, data):&#13;
        return data * (self.train_max - self.train_min) + self.train_min&#13;
&#13;
    def denorm_query(self, index, norm_value):&#13;
        range = self.train_max[index] - self.train_min[index]&#13;
        return norm_value * range + self.train_min[index]。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/zui-qiang-yi-chang-jian-ce-suan-fa-%EF%BC%8C-zi-bian-ma-qi-%20%EF%BC%81%EF%BC%81%EF%BC%9BAutoEncoder.py.html</guid><pubDate>Wed, 13 Nov 2024 15:59:17 +0000</pubDate></item><item><title>zenodo：科研数据存储库（代码托管）</title><link>https://Esgwg.github.io/ikun.github.io/post/zenodo%EF%BC%9A-ke-yan-shu-ju-cun-chu-ku-%EF%BC%88-dai-ma-tuo-guan-%EF%BC%89.html</link><description>zenodo：科研数据存储库（代码托管）。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/zenodo%EF%BC%9A-ke-yan-shu-ju-cun-chu-ku-%EF%BC%88-dai-ma-tuo-guan-%EF%BC%89.html</guid><pubDate>Wed, 13 Nov 2024 13:08:36 +0000</pubDate></item><item><title>十大降维算法</title><link>https://Esgwg.github.io/ikun.github.io/post/shi-da-jiang-wei-suan-fa.html</link><description>[十大降维算法](https://mp.weixin.qq.com/s/H50op3cJHVP5NSK78QsH1Q)&#13;
- 主成分分析&#13;
- 线性判别分析&#13;
- 核主成分分析&#13;
- 独立成分分析&#13;
- 因子分析&#13;
- t-SNE&#13;
- 多维尺度分析&#13;
- 自编码器&#13;
- 局部线性嵌入&#13;
- 奇异值分解。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/shi-da-jiang-wei-suan-fa.html</guid><pubDate>Wed, 13 Nov 2024 13:00:21 +0000</pubDate></item><item><title>VUE后台管理系统模板</title><link>https://Esgwg.github.io/ikun.github.io/post/VUE-hou-tai-guan-li-xi-tong-mo-ban.html</link><description>[VUE后台管理系统模板](http://vue.easydo.work/)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/VUE-hou-tai-guan-li-xi-tong-mo-ban.html</guid><pubDate>Wed, 13 Nov 2024 10:25:34 +0000</pubDate></item><item><title>域名测速网站</title><link>https://Esgwg.github.io/ikun.github.io/post/yu-ming-ce-su-wang-zhan.html</link><description>[域名测速网站](https://www.itdog.cn/http/)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/yu-ming-ce-su-wang-zhan.html</guid><pubDate>Wed, 13 Nov 2024 04:33:06 +0000</pubDate></item><item><title>随机外国人身份信息生成</title><link>https://Esgwg.github.io/ikun.github.io/post/sui-ji-wai-guo-ren-shen-fen-xin-xi-sheng-cheng.html</link><description>[随机外国人身份信息生成](https://www.shenfendaquan.com/)。</description><guid isPermaLink="true">https://Esgwg.github.io/ikun.github.io/post/sui-ji-wai-guo-ren-shen-fen-xin-xi-sheng-cheng.html</guid><pubDate>Tue, 12 Nov 2024 14:29:43 +0000</pubDate></item></channel></rss>